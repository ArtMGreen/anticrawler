{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading pretrained model\n",
    "\n",
    "See https://github.com/ritikjain51/CaptchaExtractor-Pytorch"
   ],
   "id": "5defce693c0d43fe"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-05T18:17:00.463239Z",
     "start_time": "2024-10-05T18:17:00.452765Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from models.captcha_model import CaptchaModel\n",
    "from datasets.dataset import Dataset\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "device = \"cpu\""
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T18:17:02.672640Z",
     "start_time": "2024-10-05T18:17:02.654923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def label_from_filepath(filepath):\n",
    "    return list(filepath.split(\"/\")[-1].split(\".\")[0])\n",
    "\n",
    "\n",
    "image_filepaths = glob.glob(os.path.abspath(os.path.join(\"../datasets/Large_Captcha_Dataset\", \"*.png\")))\n",
    "# print(image_filepaths)\n",
    "labels = np.array([label_from_filepath(x) for x in image_filepaths])\n",
    "# print(labels)\n",
    "labels_flat = labels.flatten()\n",
    "# print(labels_flat)\n",
    "\n",
    "label_encoder = LabelEncoder().fit(labels_flat)\n",
    "labels_encoded = np.apply_along_axis(label_encoder.transform, 1, labels) + 1\n",
    "# print(labels_encoded)\n",
    "\n",
    "train_X, test_X, train_y, test_y, train_target, test_target = train_test_split(\n",
    "    image_filepaths, labels_encoded, labels)\n",
    "\n",
    "train_dataset = Dataset(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    resize=(75, 300)\n",
    ")\n",
    "\n",
    "test_dataset = Dataset(\n",
    "    test_X,\n",
    "    test_y,\n",
    "    resize=(75, 300)\n",
    ")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=8,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=8\n",
    ")"
   ],
   "id": "63096124d3fbb39",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T18:27:10.623131Z",
     "start_time": "2024-10-05T18:27:10.594948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = CaptchaModel(len(label_encoder.classes_))\n",
    "model.load_state_dict(torch.load(\"../models/captcha_recognition_20_epochs.pt\", weights_only=True))\n",
    "model.to(device)\n",
    "model.eval()"
   ],
   "id": "8d52dcf6fca923d0",
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options \n\t(1) Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL model.CaptchaModel was not an allowed global by default. Please use `torch.serialization.add_safe_globals([CaptchaModel])` to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnpicklingError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[33], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m CaptchaModel(\u001B[38;5;28mlen\u001B[39m(label_encoder\u001B[38;5;241m.\u001B[39mclasses_))\n\u001B[0;32m----> 2\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../models/captcha_recognition_20_epochs.pt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m)\n\u001B[1;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[0;32m~/DataspellProjects/anticrawler/venv/lib/python3.12/site-packages/torch/serialization.py:1096\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[1;32m   1090\u001B[0m                 \u001B[38;5;28;01mreturn\u001B[39;00m _load(opened_zipfile,\n\u001B[1;32m   1091\u001B[0m                              map_location,\n\u001B[1;32m   1092\u001B[0m                              _weights_only_unpickler,\n\u001B[1;32m   1093\u001B[0m                              overall_storage\u001B[38;5;241m=\u001B[39moverall_storage,\n\u001B[1;32m   1094\u001B[0m                              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[1;32m   1095\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 1096\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(_get_wo_message(\u001B[38;5;28mstr\u001B[39m(e))) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1097\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _load(\n\u001B[1;32m   1098\u001B[0m             opened_zipfile,\n\u001B[1;32m   1099\u001B[0m             map_location,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1102\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args,\n\u001B[1;32m   1103\u001B[0m         )\n\u001B[1;32m   1104\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mmap:\n",
      "\u001B[0;31mUnpicklingError\u001B[0m: Weights only load failed. This file can still be loaded, to do so you have two options \n\t(1) Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL model.CaptchaModel was not an allowed global by default. Please use `torch.serialization.add_safe_globals([CaptchaModel])` to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
